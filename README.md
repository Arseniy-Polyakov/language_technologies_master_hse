# Language Technologies Master HSE (Языковые технологии в бизнесе и образовании)
В данном репозитории содержатся домашние работы для дисциплин магистратуры НИУ ВШЭ Санкт-Петербург "Языковые технологии в бизнесе и образовании" 2024-2026 гг.

# Data Bases (Базы данных)
В данном репозитории содержатся домашние работы по курсу "Базы данных".
1. Task 1. Домашняя работа посвящена упрощенной схеме маркетплейса. 
Была создана схема в визуальном редактора, созданы таблицы в базе данных, введены данные, 
таблицы были связаны между собой внешними ключами. 
В ходе работы было написано несколько SQL-запросов на добавление, удаление, редакторирование данных; 
а также на отбор по условиям
2. Task 2. Проект посвящен созданию базы данных и проверке лингвистических гипотез на основе данных о
параметрах сложности англоязычного текста. База данных была выполнена для pet-проекта по исследованию
оценки сложности текста и созданию автоматической системы оценивания (ссылки на статьи и github см. в 
ноутбуке text_readability.ipynb). 
В ходе работы был использован датасет с размеченными текстами согласно CEFR классификации,
были определены метрики на каждом уровне (фонологический, грамматический, лексический), а также
количественные показатели (индексы сложности) для всех текстов датасета. 
Выходные статистические данные представлены в папке files_databases и разделены на *.csv файлы для каждого уровня. 
На их основе были созданы таблицы в базе данных, были сделаны как и запросы на создание / удаление / изменение данных, 
так и на вывод, в том числе с вложенными запросами и JOIN. 
В рамках написания sql-запросов были подтверждены / опровергнуты лингвистические гипотезы (см. скрипт sql)
3. Task 3. Задание на noSQL базы данных. 
В рамках задания были выполнены запросы на создание / удаление / изменение данных, а также вывод выборок по условию
с помощью БД MongoDB. 
Данные использовались те же, что и в задании 2. 

# Functional Models (Функциональные модели в лингвистике)
1. Task 1. Задание направлено на подсчет различных индексов метафор и их визуализации
2. Task 2. Задание посвящено контент-анализу статьи Алексея Тарасова "Мертвецы начали подниматься..."

# Intro to IT (Введение в информационные технологии)
Данная папка содержит домашние задания по курсу "Введение в информационные технологии".
1. Task 1. CSV (задания на отработку использования различных методов модуля CSV Python)
2. Task 2. JSON (задания на отработку использования различных методов модуля JSON Python)
3. Task 3. Regex (задания на написание регулярных выражений)

# Machine Learning (Машинное обучение)
Данная папка содержит домашние задания по курсу "Машинное обучение".
1. Task 1. Titanic Challenge (обучение модели knn для классификации новых фич данных датасета Титаник)
2. Task 2. Vectorization (векторизация датасета русских финансовых новостей kkhubiev/russian-financial-news с помощью моделей Word2Vec и Fasttext)
3. Task 3. CNN (обучение сверточной нейронной сети (CNN) + рекуррентной нейронной сети (RNN, LSTM) для классификации и перевода видеозаписей русского жестового языка на основе корпуса Slovo; обучение сверточной нейронной сети (CNN) для классификации изображений американского жестового языка на основе датасета MNIST Sign Language)
4. Task 4. RNN (обучение рекуррентной нейронной сети для перевода текстов с карельского языка на русский на основе параллельного подкорпуса НКРЯ и самостоятельно собранного параллельного корпуса на основе произведения Калевала)

# NLP (Прикладная лингвистика)
Данный репозиторий содержит домашние работы по курсу "Введение в прикладную лингвистику".
1. Task 1. Corpus Linguistics. В ходе работы были сгенерированны примеры дореволюционных открыток на тему путешествий с помощью семейства моделей GigaChat (GigaChat, GigaCgat2, GigaChat-Max, GigaChat-Pro, GigaChat-2-Pro, GigaChat-2-Max) с помощью GigaChat API. Была определена наиболее подходящая модель для данной задачи, а также указаны минусы prompt-подхода и альтернативные способы решения.
2. Task 2. Topic Modeling. В ходе работы было проведено тематическое моделирование с помощью модели BERTopic для выявления кластеров на основе корпуса советской песни и сравнение качества результатов кластеризации с эталонными тэгами в корпусе. 
3. Task 3. Stylometric. В рамках работы был проведен стилометрический анализ по выявлению лингвистических особенностей, а также особенностей идиостиля писателей: М. Булгакова, И. Ильфа и Е. Петрова. В качестве критериев были выбраны количественные метрики текста. Также был обучен алгоритм рандомного леса для классификации текстов писателей.
4. Task 4. Sentiment Analysis. В ходе работы был обучен алгоритм машинного обучения (рандомный лес) на основе датасета ru_sentiment. Данный алгоритм был использован для выявления сентимента новостей из финансового датасета и анализа полученного результата в соответствии с финансовыми и экономическими новостями за данный период (2011-2024 гг.)
5. Task 5. Emotional Analysis. В рамках работы было проведено сравнение двух моделей распознавания эмоций в русских текстах: CEDR и SEARA. Также был обучен на датасете sagteam/cedr_v1 алгоритм полиномиальной логистической регрессии и проведено сравнение качества данного алгоритма с моделями CEDR и SEARA.
6. Task 6. NER. Работа состоит в извлечении, нормализации и визуализации топонимов (городов) с помощью библиотеки natasha, python на основе корпуса советских песен, проверки гипотез о частотности встречаемости городов в связи с тематическим делением на кластеры, а также сравнение качества извлечения именованных сущностей с большими языковыми моделями.

# Statistics (Статистика в лингвистических исследованиях)
В данной папке находятся домашние работы по дисциплине "Статистика в лингвистических исследованиях". Все работы выполнены на основе датасета eye_tracking_description.csv
1. Task 1. Dataset (Описание полей датасета)
2. Task 2. Description Statistics (Подсчет описательных статистик датасета и их визуализация)


